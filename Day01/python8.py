# 优化器
# 搜索Tensorflow Optimizer 可以查询到有哪些优化器可以使用
# 常用的有GradientDescentOptimizer（梯度下降）
# 关于梯度下降的原理可以看这篇博客
# https://blog.csdn.net/li_wen01/article/details/73222657
# 在这个优化器下根据算法的不同可以有两种选择
# 批量梯度下降法（BGD）
# 随机梯度下降法（SGD）
# 惯性原则Momentum和变化的学习效率AdaGrad

